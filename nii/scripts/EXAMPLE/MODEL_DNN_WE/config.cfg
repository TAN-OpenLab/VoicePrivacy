max_epochs_no_best   = 2
max_epochs           = 5
learning_rate        = 3e-5
network              = ./network.jsn
train                = true
train_file           = ../DATA_WE/data.nc1
val_file             = ../DATA_WE/data.nc1
weights_dist         = normal
weights_normal_sigma = 0.1
weights_normal_mean  = 0
stochastic           = true
validate_every       = 1
parallel_sequences   = 1
input_noise_sigma    = 0.1
shuffle_fractions    = true
shuffle_sequences    = false
momentum             = 0
autosave             = true

# I use WE to denote word embedding
welearning_rate      = -3e-5    # Learning rate for WE. If it is < 0, not update WE
		                # if learning_rate < 0, welearning_rate >0
				#     update WE, but not weight of network
				#     updated WE will be saved as epoch***.autosave.we
				# if learning_rate > 0, welearning_rate >0
				#     update WE, and weight of network
				#     updated WE will be saved as epoch***.autosave.we
				# if learning_rate > 0, welearning_rate <0
				#     just use WE, only update weight of network
				# 
weExternal           = 1        # turn this on to enable WE
weIDDim		     = 382      # what's the dimension index of the WE index in the input file?
weBank		     = ../RAWDATA/we.webank_s
weDim		     = 80       # total number of dimension of WE
