### EXAMPLE for MDN ###

Directory:
	RNN: the RNN network which will initialize the MDN
	RMDN: the RMDN directory

Usage:
	1. prepare and train the RNN network.
           the same procedure as the RNN example.

        2. configure the RMDN 
	   please use the RMDN/createMDNConfig.py
	   the default there configuration is 
           [2 mixture GMM for MGC, sigmoid for UV, 2 mixture GMM for Lf0, 1 mixture for BAP]
	   without sharing the variance across dimensions
	  
           ~$ cd RMDN
	   ~$ python createMDNConfig.py
	   You will see a file mdn.config, and the screen will print something like:
	   "
	   [[0, 722], [722, 723], [723, 737], [737, 888]]
	   Dimension of output of NN should be 888	
	   "
	   
	   This number is the total number of parameter for the distribution in RMDN, including
           mean, variance, mixture weight, etc. 
	   
	3. prepare the RMDN network
	   copy the network.jsn for RNN to RMDN directory.
	   use the number shown in Step.2, (e.g., 888) as the size of the layer BEFORE RMDN !

	4. prepare the config.cfg for RMDN with additional options
	   
	   # path to the mdn.config file
	   mdn_config           = ./mdn.config                  

	   # path to the RNN network, which will be used to initialize the RMDN
	   trainedModel         = ../RNN/trained_network.jsn    
	   
	   # a 1/0 controller, to control which layer should be initialized.
	   # the length of the 1/0 vector is equal to the number of layers.
	   # Usually, you can initialize all the layers except the input, last (RMDN layer),
	   # and the output layer before the last layer (actuallt, you can not initialize it
	   # using the RNN because it has a different layer size from that in RNN).
	   # in the example, only need to initialize the 2 hidden logistic layers
	   trainedModelCtr      = 01100                         

	   # default configuration 
	   wInitPara            = 20
	   # default configuration 
	   varInitPara          = 0.001

   	   # If you specify tieVariance=0 in createMDNConfig.py, set tieVariance = 0	
	   # otherwise, 1
	   tieVariance          = 0

	5. prepare the config.cfg for ARRMDN
	   basically, the same as RMDN, except
	   
	   in config.cfg
	   # the initializer is now the RMDN
	   trainedModel         = ../RMDN/trained_network.jsn
	   # the output layer should be initialized
	   trainedModelCtr      = 01110
	   # configuration for the AR, it is a vector whose length is equal to the
	   # number distributions in the MDN. The order is in accord with the 
	   # configuration in Step2.
	   # here, the configuration means
	   # 1: use 1-order AR for MGC
	   # 0: don't care about the U/V
	   # 3: use 2-order AR for F0 (the number 2 is reserved for another option)
	   # 0: don't care about the BAP
	   mdnDyn               = 1030

	   # turn on the tanh function to ensure the stability of the AR filter
	   tanhAutoReg          = 1

	   in config_syn.cfg
	   # this options should also be provided
	   tanhAutoReg          = 1
	   
 	6. More on the filters:
	   the new CURRENNT can support high order AR, but you need to select the 
	   implementation methods.
	   	   
	   How to select high order AR ? Just increase the number in mdnDyn:
	   1: use 1-order AR
	   3: use 2-order AR 
	   8: use 3-order AR
	   9: use 4-order AR
	   ...
	   N: use N-3 order AR
	   If the number is > 10, mdnDyn should be specified in this way: mdnDyn = 1_0_11_0.
	   In this case, I use 1-order AR for MGC, and 8(=11-3)-order AR for F0.
	   Note that both 1030 and 1_0_3_0 works for small digits.
	   	   

	   What's the implementation methods? It decides the method to ensure the
	   stability of the AR filter (please check the slides for the SAR papar). 
	   We can allow the filter to stable while have complex or real zeros/poles. These
	   can be implemented by using several tricks. 
	   (please check the slides about MDN in http://tonywangx.github.io/slides.html).
	   Anyway, we can specify the methods by setting tanhAutoReg

	   tanhAutoReg = 0  # (default) no guanratee on the stability for all AR GMMs
	   tanhAutoReg = 1  # all AR GMMS will be stable but only use real-valued zeros/poles
	   
	   If the order of AR is > 3, we use enable the filtes to have complex-valued zeros/poles.
	   tanhAutoReg = 1020 # use the real-valued zeros/poles for the GMM of MGC
	   	       	      # but use complex-valued zeros/poles for the GMM of F0
	   As you may noticed, the implementaion methods can be specified for each AR GMM. It will
	   be ignored for none GMM density functions.


Tips:
	1. Normally, I only train ARRMDN for 1-5 epochs since I always train the network
	   after initializing it using RMDN.
	


	   