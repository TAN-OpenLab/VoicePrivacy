random_seed          = 1811626773
max_epochs_no_best   = 10
max_epochs           = 10
network              = ./network.jsn
train                = true

train_file           = ../DATA_WAVENET/data.nc1
autosave             = true

weights_dist         = uninorm
weights_normal_sigma = 0.1
weights_normal_mean  = 0
stochastic           = true
validate_every       = 1
parallel_sequences   = 1
input_noise_sigma    = 0
shuffle_fractions    = false
shuffle_sequences    = true
momentum	     = 0

# Truncate the utterance according to this maximum length
# If the GPU memory is insufficient, please use a smaller
# value here
truncate_seq         = 10000

# Optimization option
# =0: normal SGD
# =1: ADGRAD
# =3: SGD + ADAGRAD
#     Please use OptimizerSecondLR to specify the learning rate for ADAGRAD
# =4: SGD + learning_rate decay
# =5: Adam
Optimizer            = 5
learning_rate        = 0.00001

# Configuration of the MDN layer
# please use ./createMDNConfig.py to generate this file
mdn_config           = ./mdn.config

# Conditional acoustic features (at the frame level)
#  Multiple input features will be concatenated as the acoustic feature vector
#  Here I use the mgc and quantized F0 as the conditional features
# Direction of each kind of feature, seperated by ','
ExtInputDirs         = ../RAWDATA,../RAWDATA

# File extensions of each kind of feature, seperated by ','
#  
ExtInputExts         = .mgc,.lf0_dis_class

# Dimension of each kind of features, seperated by '_'
ExtInputDims         = 60_1

# Time resolution = samplingRate * frameShift
#  here, sampling rate of waveform is 16k, frameshift is 5ms
#  resolutions = 16000 * 0.005 = 80
resolutions          = 80