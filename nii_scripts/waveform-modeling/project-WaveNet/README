###########################################################################
##  Scripts for WaveNet   ----------------------------------------------  #
## ---------------------------------------------------------------------  #
##                                                                        #
##  Copyright (c) 2018  National Institute of Informatics                 #
##                                                                        #
##  THE NATIONAL INSTITUTE OF INFORMATICS AND THE CONTRIBUTORS TO THIS    #
##  WORK DISCLAIM ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING  #
##  ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN NO EVENT    #
##  SHALL THE NATIONAL INSTITUTE OF INFORMATICS NOR THE CONTRIBUTORS      #
##  BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY   #
##  DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,       #
##  WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS        #
##  ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE   #
##  OF THIS SOFTWARE.                                                     #
###########################################################################
##                         Author: Xin Wang                               #
##                         Date:   31 Oct. 2018                           #
##                         Contact: wangxin at nii.ac.jp                  #
###########################################################################

It is recommeded to trying projects/waveform-modeling/NSF-pretrained at first.
That script contains pre-trained model and can generated waveforms.

This script demonstrate how to prepare data, train NSF, and generate speech. 

You may use the CMU-arctic database, SLT voice
(http://festvox.org/cmu_arctic/dbs_slt.html).

Please follow the steps to run the scripts

Note: 
CURRENNT is not that flexible if you are a tensorflow/theano/pyTorch/chainer user.
Please check the slides of CURRENNT on http://tonywangx.github.io/slides.html,
especially, the two slides on WaveNet:
http://tonywangx.github.io/pdfs/CURRENNT_WAVENET.pdf
http://tonywangx.github.io/pdfs/wavenet.pdf

------------------------------------
---
Step1. prepare software enviroment

1.1 pyTools:  https://github.com/nii-yamagishilab/project-CURRENNT-public
    please compile it following pyTools/README
    
1.2 CURRENNT: https://github.com/nii-yamagishilab/project-CURRENNT-public
    please compile it following CURRENNT-modified/README
    
1.3 python2, with Numpy and Scipy

---
---
Step2. For a quick test on the scripts, you can skip Step2 and Step3.
    If you want to train a full model, put data from CMU-arctic SLT to ./DATA


2.1 mel-spectrogram: please use your scripts to extract them.
    To be compatible with F0, please use a frame shift of 5ms;
    I use mel-spectrogram of 80 dimensions.
    
2.2 waveform: just download the waveform from CMU-arctic SLT.
    I used 32kHz (for historical reason).
    Waveform will be downsampled to 16kHz by the scripts.
    
2.3 put waveform in ../DATA/wav32k as *.wav,
    put mel-spec in ../DATA/mfbsp as *.mfbsp 

In fact, *.mfbsp can be any type of spectral features. You can use
mgc, mfcc, etc. As long as feature dimension and name extension are
configured in config.py, they will be loaded for network training

---
Step3. configure config.py and train_config.cfg
    
---
Step4. prepare data and train the model

    sh 00_run.sh

    Data preparation took 5 minutes on my server.
    Using a p100 GPU card, network training took 1 day
    
    If you want to shorten the number of epochs (50 by default),
    please change max_epochs in train_config.cfg

    Don't be surprised if you see the network with ~500 'layers'.
    In my implementation, each 'layer' may only correspond to a single
    operation (e.g., adding, weighting) in tensorflow.
    
    Don't be surprised if you see the training and validation sentences
    number are larger than what is provided. Utterance are truncated
    into short utterances in order to fit in the GPU. This truncation
    size is specified in CONFIGS/train_config.cfg truncate_seq=

    I uploaded my log_train in WaveNet-pretrained/MODELS/wavenet001
    
---
Step5. generate waveforms

    Put mel-spec of test set in ../TESTDATA/mfbsp
    Specify configurations in "----- Network training configuration" of config.py
    
    sh 01_gen.sh
    
    You can generate waveforms by changing gen_network_path to any of the epoch***.autosave,
    where *** denotes the training epoch.
    
--------------------------------

